# HyperlinkLaw GPU OCR Worker

Ultra-fast legal document processing with GPU-accelerated OCR.

## Features

- ğŸš€ **10-50x faster** than CPU processing
- âš¡ **GPU-accelerated** PaddleOCR with CUDA
- ğŸ“Š **Real-time progress** tracking via database
- ğŸ¯ **Index-first** processing for instant lawyer access
- ğŸ”„ **Resumable** processing with UPSERT operations
- ğŸ“ˆ **Scalable** with Redis job queue

## Performance

| Document Size | Processing Time | Cost (AWS g5.xlarge) |
|---------------|----------------|---------------------|
| 50 pages | 30-60 seconds | $0.60-1.20 |
| 200 pages | 2-4 minutes | $2.40-4.80 |
| 517 pages | 3-6 minutes | $3.60-7.20 |
| 1000+ pages | 5-10 minutes | $6.00-12.00 |

**ROI: Save $400-900 in lawyer time per document**

## Quick Deploy

### AWS (Recommended)
```bash
# Set your AWS credentials
export AWS_ACCESS_KEY_ID=your-key
export AWS_SECRET_ACCESS_KEY=your-secret
export AWS_REGION=us-east-1

# Deploy with one command
chmod +x deploy-aws.sh
./deploy-aws.sh
```

### Local Development
```bash
# Clone and setup
git clone https://github.com/yourusername/hl-ocr-worker.git
cd hl-ocr-worker

# Configure environment
cp .env.example .env
# Edit .env with your database credentials

# Build and run
docker-compose up --build
```

## Configuration

Set these environment variables:

```bash
# Database (required)
DB_HOST=your-database-host
DB_PORT=5432
DB_NAME=your-database-name
DB_USER=your-database-user
DB_PASSWORD=your-database-password

# Redis (required)
REDIS_URL=redis://localhost:6379

# Optional
CUDA_VISIBLE_DEVICES=0  # GPU device ID
```

## Usage

### Via Job Queue (Production)
```python
import redis
import json

redis_client = redis.Redis.from_url('redis://your-redis-url')

# Queue OCR job
job = {
    "document_id": "uuid-here",
    "pdf_url": "https://your-storage/document.pdf",
    "total_pages": 517,
    "priority": "high"
}

redis_client.lpush('ocr_jobs', json.dumps(job))
```

### Via API (Development)
```bash
# Health check
curl http://localhost:8000/health

# Process document directly
curl -X POST http://localhost:8000/process \
  -H "Content-Type: application/json" \
  -d '{
    "document_id": "uuid-here",
    "pdf_url": "https://your-storage/document.pdf", 
    "total_pages": 517
  }'
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Replit App    â”‚â”€â”€â”€â–¶â”‚   Redis Queue    â”‚â”€â”€â”€â–¶â”‚  GPU Worker     â”‚
â”‚  (Control)      â”‚    â”‚   (Jobs)         â”‚    â”‚  (Processing)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                               â”‚
         â–¼                                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Database      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   Object Store  â”‚
â”‚  (Progress)     â”‚        Results             â”‚   (PDFs)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Scaling

### Single GPU (Small Firms)
- **Instance**: AWS g5.xlarge (1x A10G GPU)
- **Cost**: ~$100-200/month
- **Capacity**: 10-20 documents/day

### Multi-GPU (Large Firms)
- **Instance**: AWS g5.12xlarge (4x A10G GPUs) 
- **Cost**: ~$1000-2000/month
- **Capacity**: 100+ documents/day
- **ROI**: $50,000+ in saved lawyer time

### Auto-Scaling
```bash
# Deploy auto-scaling cluster
aws ecs create-cluster --cluster-name legal-ocr-cluster
aws ecs create-service \
  --cluster legal-ocr-cluster \
  --service-name gpu-workers \
  --desired-count 4 \
  --task-definition gpu-worker-task
```

## Monitoring

```bash
# Check worker logs
docker-compose logs -f gpu-worker

# Monitor Redis queue
redis-cli llen ocr_jobs

# Check GPU usage
nvidia-smi

# Health check
curl http://localhost:8000/health
```

## Troubleshooting

### GPU Not Detected
```bash
# Check CUDA installation
nvidia-smi
docker run --rm --gpus all nvidia/cuda:12.1.0-runtime-ubuntu22.04 nvidia-smi
```

### Memory Issues
```bash
# Monitor GPU memory
watch -n 1 nvidia-smi

# Reduce batch size in worker.py
# Lower DPI in render_page_optimized()
```

### Performance Optimization
- Use SSD storage for temp files
- Increase Redis memory limit
- Scale to multiple GPU workers
- Use higher GPU instance types (A100, H100)

## Legal Document Optimization

The worker is specifically optimized for legal documents:

- **Text Layer Detection**: Skips OCR for pages with existing text
- **Legal Confidence Thresholds**: Optimized for 85%+ accuracy
- **Page Enhancement**: Preprocessing for scanned court documents  
- **Index-First Processing**: Prioritizes table of contents
- **Error Recovery**: Continues processing despite individual page failures

## Support

For issues or questions:
- Check logs: `docker-compose logs -f`
- Health endpoint: `http://your-ip:8000/health`
- GPU monitoring: `nvidia-smi`

**Transform your legal document processing from hours to minutes!** âš¡ğŸ“„